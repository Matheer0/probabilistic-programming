{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementions\n",
    "\n",
    "So far, we have been using what is known as Gen's dynamic modelling language which provides an implementation of the `@gen` macro to define generative functions. In this lecture, we will examine how these work under the hood. First, let's load Gen and the `Distributions` Julia library which provides basic sampling and scoring support for commonly used probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen\n",
    "using Distributions\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand how Gen works, we will introduce a simplfied variant of the language. First, instead of using the `@gen` macro to define generative functions, we will define them directly. Amongst other things, the macro can be understood as desugaring the `~` operator. Instead of using this operator, we will assume that we have access to a `sample` function which takes three arguments: (i) the name of the sample (ii) the distribution to sample from and (iii) the arguments of the distribution to be sampled from. We will assume that the implementation of the sample function is passed as an argument to our generative function (we can think of the `@gen` macro as adding this argument to the function definition). Here are implementations of `flip_biased_coin` in both Gen and GenLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function flip_biased_coin(N)\n",
    "    θ ~ beta(1,1)\n",
    "    [{:flip => i} ~ bernoulli(θ)  for i in 1:N]\n",
    "end;\n",
    "\n",
    "function flip_biased_coin_lite(sample, N)\n",
    "    θ = sample(:θ, Beta, (1,1))\n",
    "    [sample(:flip => i, Bernoulli, θ) for i=1:N]\n",
    "end;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the line model translated into our new idiom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol,Any}(), Dict{Symbol,Any}(), Type[Array{Float64,1}], false, Union{Nothing, Some{Any}}[nothing], ##line_model#254, Bool[0], false), Trie{Any,Gen.ChoiceOrCallRecord}(Dict{Any,Gen.ChoiceOrCallRecord}(:ϵ => Gen.ChoiceOrCallRecord{Float64}(-2.1502884475932325, -2.2051284977070607, NaN, true),:m => Gen.ChoiceOrCallRecord{Float64}(-1.8081429877652804, -2.5536290653070504, NaN, true),:b => Gen.ChoiceOrCallRecord{Float64}(1.1151036782510546, -1.767517740420747, NaN, true)), Dict{Any,Trie{Any,Gen.ChoiceOrCallRecord}}(:y => Trie{Any,Gen.ChoiceOrCallRecord}(Dict{Any,Gen.ChoiceOrCallRecord}(4 => Gen.ChoiceOrCallRecord{Float64}(-10.907533725375393, -2.986761482679123, NaN, true),2 => Gen.ChoiceOrCallRecord{Float64}(-4.714461072848758, -2.5647084189035767, NaN, true),3 => Gen.ChoiceOrCallRecord{Float64}(-10.572826487446568, -3.3676665541097575, NaN, true),5 => Gen.ChoiceOrCallRecord{Float64}(-7.21712972299034, -2.461881768528303, NaN, true),1 => Gen.ChoiceOrCallRecord{Float64}(-0.052316344414370386, -2.459743682638863, NaN, true)), Dict{Any,Trie{Any,Gen.ChoiceOrCallRecord}}()))), false, -20.36703721029448, 0.0, ([1.0, 2.0, 3.0, 4.0, 5.0],), [-0.052316344414370386, -4.714461072848758, -10.572826487446568, -10.907533725375393, -7.21712972299034])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@gen function line_model(xs::Vector{Float64})\n",
    "    n = length(xs)\n",
    "    \n",
    "    m ~ normal(0, 1)\n",
    "    b ~ normal(0, 2)\n",
    "    ϵ ~ normal(0,2.5)\n",
    "\n",
    "    ys=[{:y => i} ~ normal(m * x + b, ϵ^2) for (i, x) in enumerate(xs)]\n",
    "end;\n",
    "\n",
    "function line_model_lite(sample, xs)\n",
    "    n = length(xs)\n",
    "\n",
    "    m = sample(:m, Normal, (0, 1))\n",
    "    b = sample(:b, Normal, (0, 2))\n",
    "    ϵ = sample(:ϵ, Normal, (0, 2.5))\n",
    "    \n",
    "    ys = [sample(:y => i, Normal, (m * x + b, ϵ^2)) for (i, x) in enumerate(xs)]\n",
    "end;\n",
    "\n",
    "t=Gen.simulate(line_model,([1.,2.,3.,4.,5.],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make use of these implementations of generative functions, we will need to define sample and pass it in. Let's see how we can implement a version of `simulate` using this technique.\n",
    "\n",
    "Recal that simulate takes a generative function and its arguments and returns a trace representing a sample from the generative function with those arguments. We will need to represent a few things in this program.\n",
    "\n",
    " - **The set of random choices**. For this, we will simply use a dictionary (hashtable) with keys being sequences of symbols such as `:f => 1`.\n",
    " - **The score of the sample**. This will be the log density or probability of each random choice made during sampling.\n",
    " - **The trace**. For this, we will make use of a simple tuple with the following elements:\n",
    "     1. The generative function\n",
    "     2. The arguments the function was called on.\n",
    "     3. The return value of the function.\n",
    "     4. The set of choices made during sampling.\n",
    "     5. The log probability of the trace that was sampled.\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(gen_func = flip_biased_coin_lite, args = (1000,), retval = Bool[0, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 0, 1, 1, 1, 1, 1], choices = Dict{Any,Any}((:flip => 899) => true,(:flip => 930) => true,(:flip => 659) => true,(:flip => 298) => false,(:flip => 706) => true,(:flip => 10) => true,(:flip => 176) => true,(:flip => 686) => false,(:flip => 523) => true,(:flip => 467) => true…), score = -431.6268812215542)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simulate_lite(gen_func, args)\n",
    "    \n",
    "    # initialise the set of choices to an empty dictionary\n",
    "    choices = Dict()\n",
    "    \n",
    "    # Initialize the density at 1\n",
    "    score = 0.0\n",
    "    \n",
    "    # An implementation of the sample function\n",
    "    function sample_(name, distribution, dist_args)\n",
    "\n",
    "        \n",
    "        # Create an instance of the relevant distribution from the Distributions library\n",
    "        dist = distribution(dist_args...) \n",
    " \n",
    "        # Sample the value\n",
    "        value = rand(dist)\n",
    "        \n",
    "        # Score the value\n",
    "        density = Distributions.logpdf(dist, value)\n",
    "        \n",
    "        # Update the log density with the value\n",
    "        score += density\n",
    "        \n",
    "        # Record the sampled value with its name\n",
    "        choices[name] = value\n",
    "        return(value)\n",
    "    end\n",
    "\n",
    "    # Call the generative function with the sample function defined\n",
    "    retval = gen_func(sample_, args...)\n",
    "    \n",
    "    # return trace as a named tuple\n",
    "    (gen_func=gen_func, args=args, retval=retval, choices=choices, score=score)\n",
    "\n",
    "end;\n",
    "\n",
    "\n",
    "simulate_lite(flip_biased_coin_lite, (1000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a more interesting function is the implementation of `generate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_lite(gen_func, args, condition)\n",
    "    \n",
    "    choices = Dict()\n",
    "    score = 0.0\n",
    "    \n",
    "    # The importance weight = the likelihood  in this case.\n",
    "    weight = 0.0 \n",
    "    \n",
    "    function sample_(name, distribution, dist_args)\n",
    "        \n",
    "        dist = distribution(dist_args...)\n",
    "        \n",
    "        # Check to see if the random choice is already in the constraints\n",
    "        if name in keys(condition)\n",
    "            \n",
    "            # If the random choice is conditioned, then just score it and set it in the choices dictionary\n",
    "            score += logpdf(dist, condition[name])\n",
    "            weight += logpdf(dist, condition[name])\n",
    "            choices[name] = condition[name]\n",
    "        else\n",
    "            \n",
    "            # Otherwise, sample it as in simulate and do NOT update the weight.\n",
    "            value = rand(dist)\n",
    "            \n",
    "            # Critically, score is updated in both places.\n",
    "            score += logpdf(dist, value)\n",
    "            choices[name] = value\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    retval = gen_func(sample_, args...)\n",
    "    trace = (gen_func=gen_func, args=args, retval=retval, choices=choices, score=score)\n",
    "    return weight, trace\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,jl:light",
   "text_representation": {
    "extension": ".jl",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.10.0"
   }
  },
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
